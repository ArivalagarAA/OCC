{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdrTD3ONzAFG",
        "outputId": "1128bc7b-5619-48b1-8f58-bffd557b4c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode, split, count, min, max"
      ],
      "metadata": {
        "id": "gGHnRO5Rz572"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"Job opportunities.xlsx\")\n",
        "df.to_csv(\"Job opportunities.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "PKF4Bp1I0nDH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6228c5bc",
        "outputId": "37b9c07f-6d09-42d5-860c-e6758550e959"
      },
      "source": [
        "# Convert the pandas DataFrame to a Spark DataFrame\n",
        "df_spark = spark.createDataFrame(df)\n",
        "\n",
        "# Now you can perform the groupBy operation\n",
        "df_spark.groupBy(\"Location\").count().show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|  Location|count|\n",
            "+----------+-----+\n",
            "| Edinburgh|   35|\n",
            "|Manchester|   43|\n",
            "|   Glasgow|   39|\n",
            "|   Cardiff|   29|\n",
            "|    London|   28|\n",
            "|Birmingham|   48|\n",
            "| Sheffield|   32|\n",
            "|   Bristol|   24|\n",
            "| Newcastle|   15|\n",
            "|     Leeds|   35|\n",
            "| Liverpool|   16|\n",
            "|Nottingham|   20|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.groupBy(\"Company\").count().orderBy(col(\"count\").desc()).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOLTfY_N01V9",
        "outputId": "18c948ee-dd03-48ec-9a5b-0280c9a70370"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|       Company|count|\n",
            "+--------------+-----+\n",
            "| Data Insights|   16|\n",
            "|Cloud Analysts|   12|\n",
            "| Web Creations|   12|\n",
            "|   IT Training|   11|\n",
            "|   SecureGuard|    9|\n",
            "+--------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.groupBy(\"Experience Level\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voE0dgGa04bK",
        "outputId": "a3ac746c-7aea-4458-f83b-1ab459fbcb4c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+\n",
            "|Experience Level|count|\n",
            "+----------------+-----+\n",
            "|          Senior|   70|\n",
            "|     Entry-Level|   17|\n",
            "|       Mid-Level|  216|\n",
            "|          Junior|   58|\n",
            "|      Internship|    3|\n",
            "+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.select(\"Industry\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X6rDkuz08ZU",
        "outputId": "c03bb94d-d92b-47b2-8a21-02a70568f0f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            Industry|\n",
            "+--------------------+\n",
            "|           Education|\n",
            "|               Audit|\n",
            "|               Sales|\n",
            "|Software Development|\n",
            "| Business Continuity|\n",
            "|            Security|\n",
            "|         IT Analysis|\n",
            "|    Machine Learning|\n",
            "|     Cloud Computing|\n",
            "|         IT Services|\n",
            "|   Change Management|\n",
            "|          Networking|\n",
            "|              Ethics|\n",
            "|       Data Analysis|\n",
            "|    Data Engineering|\n",
            "|  Mobile Development|\n",
            "|   Quality Assurance|\n",
            "|    Asset Management|\n",
            "|            Research|\n",
            "|        Data Privacy|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.filter(col(\"Required Skills\").like(\"%Python%\")).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxpbCncT0_Jy",
        "outputId": "fc642450-c045-49c4-9ec2-431b8cface08"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.groupBy(\"Job Title\").count().orderBy(col(\"count\").desc()).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UwdUNWg1Btg",
        "outputId": "9206b26e-81b2-4f0e-c438-d0300597f744"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|           Job Title|count|\n",
            "+--------------------+-----+\n",
            "|IT Support Specia...|   16|\n",
            "|Cloud Solutions A...|   12|\n",
            "|Full-stack Developer|   12|\n",
            "|          IT Trainer|   11|\n",
            "|Cybersecurity Ana...|    9|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.select(min(\"Date Posted\").alias(\"Earliest\"), max(\"Date Posted\").alias(\"Latest\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf--AmJ71FF5",
        "outputId": "037bafe5-9b09-4cc4-ed24-ad2bdea45845"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+\n",
            "|           Earliest|             Latest|\n",
            "+-------------------+-------------------+\n",
            "|2019-01-10 00:00:00|2023-12-31 00:00:00|\n",
            "+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}